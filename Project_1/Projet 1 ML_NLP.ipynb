{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPANvuiX6syE60LxIiWyxt9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":112,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q2pAN7chGHw_","executionInfo":{"status":"ok","timestamp":1699968425752,"user_tz":-60,"elapsed":7298,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}},"outputId":"ea952a76-92b5-460a-9efb-3b5c45205097"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.23.5)\n","fatal: destination path 'project1-2023' already exists and is not an empty directory.\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["!pip install rank_bm25\n","!git clone https://github.com/cr-nlp/project1-2023.git\n","\n","import urllib.request as re\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import numpy as np\n","from collections import defaultdict\n","import nltk\n","import math\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","\n","def loadNFCorpus():\n","\tdir = \"./project1-2023/\"\n","\tfilename = dir +\"dev.docs\"\n","\n","\tdicDoc={}\n","\twith open(filename) as file:\n","\t\tlines = file.readlines()\n","\tfor line in lines:\n","\t\ttabLine = line.split('\\t')\n","\t\t#print(tabLine)\n","\t\tkey = tabLine[0]\n","\t\tvalue = tabLine[1]\n","\t\t#print(value)\n","\t\tdicDoc[key] = value\n","\tfilename = dir + \"dev.all.queries\"\n","\tdicReq={}\n","\twith open(filename) as file:\n","\t\tlines = file.readlines()\n","\n","\tfor line in lines:\n","\t\ttabLine = line.split('\\t')\n","\t\tkey = tabLine[0]\n","\t\tvalue = tabLine[1]\n","\t\tdicReq[key] = value\n","\n","\tfilename = dir + \"dev.2-1-0.qrel\"\n","\tdicReqDoc=defaultdict(dict)\n","\twith open(filename) as file:\n","\t\tlines = file.readlines()\n","\tfor line in lines:\n","\t\ttabLine = line.strip().split('\\t')\n","\t\treq = tabLine[0]\n","\t\tdoc = tabLine[2]\n","\t\tscore = int(tabLine[3])\n","\t\tdicReqDoc[req][doc]=score\n","\treturn dicDoc, dicReq, dicReqDoc\n"]},{"cell_type":"code","source":["\tdicDoc, dicReq, dicReqDoc = loadNFCorpus()"],"metadata":{"id":"lq-R_gYKGK8g","executionInfo":{"status":"ok","timestamp":1699969920889,"user_tz":-60,"elapsed":329,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["def text2TokenList(text):\n","\tstopword = stopwords.words('english')\n","\t#print(\"LEN DE STOPWORD=\",len(stopword))\n","\tword_tokens = word_tokenize(text.lower())\n","\tword_tokens_without_stops = [word for word in word_tokens if word not in stopword and len(word)>2]\n","\treturn word_tokens_without_stops\n"],"metadata":{"id":"ED2fooPbMxpX","executionInfo":{"status":"ok","timestamp":1699969922278,"user_tz":-60,"elapsed":7,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":139,"outputs":[]},{"cell_type":"code","source":["def docsandreqsToKeep(startDoc, endDoc):\n","\n","    dicDoc, dicReq, dicReqDoc = loadNFCorpus()\n","\n","    docsToKeep = []\n","    reqsToKeep = []\n","    dicReqDocToKeep = defaultdict(dict)\n","\n","    i = startDoc\n","    for reqId in dicReqDoc:\n","        if i > (endDoc - startDoc):  # nbDocsToKeep:\n","            break\n","        for docId in dicReqDoc[reqId]:\n","            dicReqDocToKeep[reqId][docId] = dicReqDoc[reqId][docId]\n","            docsToKeep.append(docId)\n","            i = i + 1\n","        reqsToKeep.append(reqId)\n","    docsToKeep = list(set(docsToKeep))\n","\n","    return docsToKeep, reqsToKeep, dicReqDocToKeep"],"metadata":{"id":"EUvkWT5SUWnf","executionInfo":{"status":"ok","timestamp":1699969922909,"user_tz":-60,"elapsed":3,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":140,"outputs":[]},{"cell_type":"code","source":["docsToKeep, reqsToKeep, dicReqDocToKeep = docsandreqsToKeep(0,150)"],"metadata":{"id":"-ZEVv2XlRn1N","executionInfo":{"status":"ok","timestamp":1699969923595,"user_tz":-60,"elapsed":4,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":141,"outputs":[]},{"cell_type":"code","source":["from rank_bm25 import BM25Okapi\n","def Tokenize(docsToKeep, reqsToKeep,dicDoc,dicReq):\n","    corpusDocTokenList = []\n","    corpusReqTokenList = {}\n","    corpusDicoDocName={}\n","    i = 0\n","    for k in docsToKeep:\n","      docTokenList = text2TokenList(dicDoc[k])\n","      corpusDocTokenList.append(docTokenList)\n","      corpusDicoDocName[k] = i\n","      i = i + 1\n","\n","    #print(\"reqs...\")\n","    corpusReqName=[]\n","    corpusDicoReqName={}\n","    i = 0\n","    for k in reqsToKeep:\n","      reqTokenList = text2TokenList(dicReq[k])\n","      corpusReqTokenList[k] = reqTokenList\n","      corpusReqName.append(k)\n","      corpusDicoReqName[k] = i\n","      i = i + 1\n","    return corpusDocTokenList,corpusDicoDocName,corpusReqTokenList,corpusReqName,corpusDicoReqName\n","    #print(\"bm25 doc indexing...\")\n"],"metadata":{"id":"--29Eje_Pswq","executionInfo":{"status":"ok","timestamp":1699969923963,"user_tz":-60,"elapsed":6,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":142,"outputs":[]},{"cell_type":"code","source":["corpusDocTokenList,corpusDicoDocName,corpusReqTokenList,corpusReqName,corpusDicoReqName = Tokenize(docsToKeep, reqsToKeep,dicDoc,dicReq)"],"metadata":{"id":"w36myNBlcxUC","executionInfo":{"status":"ok","timestamp":1699969925710,"user_tz":-60,"elapsed":785,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":143,"outputs":[]},{"cell_type":"code","source":["def init_vb(corpusDocTokenList):\n","        nd = {}  # word -> number of documents with word\n","        num_doc = 0\n","        doc_len=[]\n","        doc_freqs=[]\n","        corpus_size=0\n","        avgdl=0\n","        for document in corpusDocTokenList:\n","            doc_len.append(len(document))\n","            num_doc += len(document)\n","\n","            frequencies = {}\n","            for word in document:\n","                if word not in frequencies:\n","                    frequencies[word] = 0\n","                frequencies[word] += 1\n","            doc_freqs.append(frequencies)\n","\n","            for word, freq in frequencies.items():\n","                try:\n","                    nd[word]+=1\n","                except KeyError:\n","                    nd[word] = 1\n","\n","            corpus_size += 1\n","\n","        avgdl = num_doc / corpus_size\n","        return num_doc,doc_len,doc_freqs,corpus_size,avgdl,nd\n","\n","def calc_idf(nd,corpus_size,epsilon=0.25):\n","    \"\"\"\n","    Calculates frequencies of terms in documents and in corpus.\n","    This algorithm sets a floor on the idf values to eps * average_idf\n","    \"\"\"\n","    # collect idf sum to calculate an average idf for epsilon value\n","    idf_sum = 0\n","    dicidf={}\n","    # collect words with negative idf to set them a special epsilon value.\n","    # idf can be negative if word is contained in more than half of documents\n","    negative_idfs = []\n","    for word, freq in nd.items():\n","        idf = math.log(corpus_size - freq + 0.5) - math.log(freq + 0.5)\n","        dicidf[word] = idf\n","        idf_sum += idf\n","        if idf < 0:\n","           negative_idfs.append(word)\n","    average_idf = idf_sum / len(dicidf)\n","    eps = epsilon * average_idf\n","    for word in negative_idfs:\n","        dicidf[word] = eps\n","    return dicidf\n","\n","def Get_score(corpusDocTokenList,query,k1=1.5,b=0.75):\n","\n","  num_doc,doc_len,doc_freqs,corpus_size,avgdl,nd = init_vb(corpusDocTokenList)\n","\n","  score = np.zeros(len(corpusDocTokenList))\n","  dicidf = calc_idf(nd,corpus_size)\n","  doc_len = np.array(doc_len)\n","\n","\n","  for q in query:\n","      q_freq = np.array([(doc.get(q) or 0) for doc in doc_freqs])\n","      score += (dicidf.get(q) or 0) * (q_freq * (k1 + 1) /(q_freq + k1 * (1 - b + b * doc_len / avgdl)))\n","  return score"],"metadata":{"id":"zg8JnsJnDzVN","executionInfo":{"status":"ok","timestamp":1699969925711,"user_tz":-60,"elapsed":5,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"G7DRKvNMS78o","executionInfo":{"status":"ok","timestamp":1699969926951,"user_tz":-60,"elapsed":20,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["  num_doc,doc_len,doc_freqs,corpus_size,avgdl,nd = init_vb(corpusDocTokenList)\n"],"metadata":{"id":"9kbt0Dt7ZJBm","executionInfo":{"status":"ok","timestamp":1699969927370,"user_tz":-60,"elapsed":6,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":145,"outputs":[]},{"cell_type":"code","source":["  from sklearn.metrics import ndcg_score\n","\n","  def Scoring(corpusDocTokenList,corpusDicoDocName,corpusReqTokenList,corpusReqName,corpusDicoReqName):\n","\n","    #bm25 = BM25Okapi(corpusDocTokenList)\n","    #bm25 = Get_score(corpusDocTokenList)#,reqTokenList)\n","\n","    ndcgCumul=0\n","    corpusReqVec={}\n","    ndcgBM25Cumul=0\n","    nbReq=0\n","    ndcgTop=5\n","\n","    for req in corpusReqTokenList:\n","\n","      reqTokenList = corpusReqTokenList[req]\n","      #doc_scores = bm25.get_scores(reqTokenList)\n","      doc_scores = Get_score_2(corpusDocTokenList,reqTokenList)\n","      trueDocs = np.zeros(len(corpusDocTokenList))\n","\n","      for docId in corpusDicoDocName:\n","        if req in dicReqDocToKeep:\n","          if docId in dicReqDocToKeep[req]:\n","            #get position docId\n","            posDocId = corpusDicoDocName[docId]\n","            trueDocs[posDocId] = dicReqDocToKeep[req][docId]\n","            #print(\"TOKEEP=\",docId)\n","            #print(trueDocs)\n","      ndcgBM25Cumul = ndcgBM25Cumul + ndcg_score([trueDocs], [doc_scores],k=ndcgTop)\n","      nbReq = nbReq + 1\n","    ndcgBM25Cumul = ndcgBM25Cumul / nbReq\n","    print(\"ndcg bm25=\",ndcgBM25Cumul)\n","    return ndcgBM25Cumul"],"metadata":{"id":"nINJkYvUPtdi","executionInfo":{"status":"ok","timestamp":1699969928231,"user_tz":-60,"elapsed":5,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":146,"outputs":[]},{"cell_type":"code","source":["Scoring(corpusDocTokenList,corpusDicoDocName,corpusReqTokenList,corpusReqName,corpusDicoReqName)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kUzXBkmpfWt6","executionInfo":{"status":"ok","timestamp":1699969946522,"user_tz":-60,"elapsed":17389,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}},"outputId":"753f7376-2e65-409f-8cef-8d8eb9f29a80"},"execution_count":147,"outputs":[{"output_type":"stream","name":"stdout","text":["ndcg bm25= 0.20395955831078683\n"]},{"output_type":"execute_result","data":{"text/plain":["0.20395955831078683"]},"metadata":{},"execution_count":147}]},{"cell_type":"code","source":[" for req in corpusReqTokenList:\n","  reqTokenList = corpusReqTokenList[req]\n","\n","  score= Get_score(corpusDocTokenList,reqTokenList)"],"metadata":{"id":"OO-yIM0iWEaY","executionInfo":{"status":"ok","timestamp":1699957294515,"user_tz":-60,"elapsed":607,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["from gensim.models import Word2Vec\n","\n","import gensim.downloader\n","\n","model = gensim.downloader.load('glove-wiki-gigaword-200')\n","\n","#model = Word2Vec(sentences=traintokencorpus, vector_size=100, window=5, min_count=1, workers=4)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y-fQmxR2Nvna","executionInfo":{"status":"ok","timestamp":1699969149884,"user_tz":-60,"elapsed":162525,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}},"outputId":"ceb4b677-05f0-49dc-da5e-ffa60b4787c6"},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 252.1/252.1MB downloaded\n"]}]},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","def Get_score_2(corpusDocTokenList,query):\n","\n","  query_word2vec = np.array([model[word] for word in query if word in model])\n","\n","\n","  cosine_sim_word2vec = np.array([np.mean([cosine_similarity(query_word2vec[wordo].reshape(1,-1), model[word].reshape(1, -1)).flatten()[0] for word in corpusDocTokenList[a] for wordo in range(len(query_word2vec)) if word in model],axis=0)\\\n","                        for a in range(len(corpusDocTokenList))])\n","  return cosine_sim_word2vec\n"],"metadata":{"id":"gW2PMOyrS-h7","executionInfo":{"status":"ok","timestamp":1699970451581,"user_tz":-60,"elapsed":244,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}}},"execution_count":153,"outputs":[]},{"cell_type":"code","source":["query_word2vec"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvLhbAYMHk3A","executionInfo":{"status":"ok","timestamp":1699970179139,"user_tz":-60,"elapsed":292,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}},"outputId":"fdbd35bf-ecb2-4abd-968b-2ae9e0862938"},"execution_count":148,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([-0.04545643,  0.02769067,  0.56294966], dtype=float32),\n"," array([-0.07642844,  0.04368665,  0.5795835 ], dtype=float32),\n"," array([-0.04606264,  0.04265467,  0.51916176], dtype=float32),\n"," array([-0.06154141,  0.02712312,  0.4563036 ], dtype=float32)]"]},"metadata":{},"execution_count":148}]},{"cell_type":"code","source":["Get_score_2(corpusDocTokenList,corpusReqTokenList['PLAIN-1'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"id":"YEkcuvCXaVCy","executionInfo":{"status":"error","timestamp":1699971595400,"user_tz":-60,"elapsed":1140177,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}},"outputId":"7fc949df-6d1a-486e-d311-32e1f784afa4"},"execution_count":154,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-154-dbec6770c086>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGet_score_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpusDocTokenList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorpusReqTokenList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PLAIN-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-153-2524b6932385>\u001b[0m in \u001b[0;36mGet_score_2\u001b[0;34m(corpusDocTokenList, query)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   cosine_sim_word2vec = np.array([np.mean([cosine_similarity(query_word2vec[wordo].reshape(1,-1), model[word].reshape(1, -1)).flatten()[0] for word in corpusDocTokenList[a] for wordo in range(len(query_word2vec)) if word in model],axis=0)\\\n\u001b[0m\u001b[1;32m      9\u001b[0m                         for a in range(len(corpusDocTokenList))])\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_sim_word2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-153-2524b6932385>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   cosine_sim_word2vec = np.array([np.mean([cosine_similarity(query_word2vec[wordo].reshape(1,-1), model[word].reshape(1, -1)).flatten()[0] for word in corpusDocTokenList[a] for wordo in range(len(query_word2vec)) if word in model],axis=0)\\\n\u001b[0m\u001b[1;32m      9\u001b[0m                         for a in range(len(corpusDocTokenList))])\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_sim_word2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-153-2524b6932385>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   cosine_sim_word2vec = np.array([np.mean([cosine_similarity(query_word2vec[wordo].reshape(1,-1), model[word].reshape(1, -1)).flatten()[0] for word in corpusDocTokenList[a] for wordo in range(len(query_word2vec)) if word in model],axis=0)\\\n\u001b[0m\u001b[1;32m      9\u001b[0m                         for a in range(len(corpusDocTokenList))])\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_sim_word2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1393\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["query_word2vec"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1PoZPIGAFACj","executionInfo":{"status":"ok","timestamp":1699971602613,"user_tz":-60,"elapsed":289,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}},"outputId":"1be334fb-e142-4bfd-d1a6-eb0db94ead89"},"execution_count":155,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([-0.04545643,  0.02769067,  0.56294966], dtype=float32),\n"," array([-0.07642844,  0.04368665,  0.5795835 ], dtype=float32),\n"," array([-0.04606264,  0.04265467,  0.51916176], dtype=float32),\n"," array([-0.06154141,  0.02712312,  0.4563036 ], dtype=float32)]"]},"metadata":{},"execution_count":155}]},{"cell_type":"code","source":["Get_score(corpusDocTokenList,corpusReqTokenList['PLAIN-1'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgSNxd1kVvkg","executionInfo":{"status":"ok","timestamp":1699959475052,"user_tz":-60,"elapsed":771,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}},"outputId":"8fb8abef-17b1-493a-c7e1-835ea17dfc87"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([315.76514397,  55.49115531,  85.8978511 , 236.30320682,\n","       128.98258025, 182.88338228, 158.17910857, 151.16683625,\n","       141.42214796,  64.94309814,  60.7362493 ,  79.27589656,\n","       162.45939749,  73.0887188 , 135.8151554 ,  38.24943811,\n","       126.54801046, 259.53255952, 140.65161621, 527.38803394,\n","       173.89832714,  78.93975084,  76.23746938, 309.11287953,\n","       883.9652338 , 218.66399796,  77.96489064,  91.38049014,\n","       141.93189619, 134.53659709, 346.0772379 , 110.31245056,\n","        96.13223987, 169.23244499, 167.54699424, 212.92510528,\n","        52.04778373,  93.36418667,  80.50929588, 143.65834223,\n","       325.27245992,  67.46323317, 115.27236995, 319.36550771,\n","       133.43666882, 126.41327688, 255.62933675, 152.30171819,\n","       205.71112885, 199.89612992,   2.12717939,  44.5224862 ,\n","        88.09727202,  88.44759774, 171.48094194, 142.08648354,\n","       104.19696708, 340.62076947,  79.24539543,  12.70927888,\n","        61.43545935,  47.17334829, 583.61699782, 134.08649828,\n","        44.40538121,  83.9942474 , 140.35717726,  84.77463612,\n","        86.52055074,  61.46789602, 124.20872724, 337.36574197,\n","        14.91253134, 374.29249488, 105.30408658, 515.16041087,\n","       123.85183543,  26.41386767, 134.25101584, 164.29761026,\n","       246.13275582, 122.13804604, 149.32664245, 342.75875184,\n","       311.74674759, 382.35100105,  68.92442538, 498.18096506,\n","        61.5434903 ,  75.79173024, 219.62768519,  33.0838211 ,\n","        42.16927178,  92.00241279,  49.03107499,  54.48519813,\n","       298.96990639, 247.73136217, 127.97988122,  88.32504492,\n","       277.18706648,  98.69499809, 302.20911552, 106.99439314,\n","       132.9170767 , 148.28757283, 218.2267939 , 150.29401931])"]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["query_word2vec = [np.mean([model.wv[word] for word in corpusReqTokenList[query]if word in model.wv],axis=0) for query in corpusReqTokenList.keys() ]\n","query_word2vec"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pfmGeu0kOx_a","executionInfo":{"status":"ok","timestamp":1699956742169,"user_tz":-60,"elapsed":11,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}},"outputId":"f2afb4ca-32af-46c9-98a5-334eea79b0d1"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([-0.04545643,  0.02769067,  0.56294966], dtype=float32),\n"," array([-0.07642844,  0.04368665,  0.5795835 ], dtype=float32),\n"," array([-0.04606264,  0.04265467,  0.51916176], dtype=float32),\n"," array([-0.06154141,  0.02712312,  0.4563036 ], dtype=float32)]"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["np.array(query_word2vec).reshape(1, -1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDMfZz3MQ2va","executionInfo":{"status":"ok","timestamp":1699956797028,"user_tz":-60,"elapsed":8,"user":{"displayName":"Paul Runavot","userId":"06521486679719752379"}},"outputId":"8852d24e-a492-479a-dde8-1d3dcb06368c"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.04545643,  0.02769067,  0.56294966, -0.07642844,  0.04368665,\n","         0.5795835 , -0.04606264,  0.04265467,  0.51916176, -0.06154141,\n","         0.02712312,  0.4563036 ]], dtype=float32)"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["tfidf_vectorizer = TfidfVectorizer()\n","tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n","\n","tokenized_documents = [doc.split() for doc in documents]\n","word2vec_model = Word2Vec(sentences=tokenized_documents, vector_size=100, window=5, min_count=1, workers=4)\n","\n","query_tfidf = tfidf_vectorizer.transform([query])\n","query_word2vec = np.mean([word2vec_model.wv[word] for word in query.split() if word in word2vec_model.wv], axis=0)\n"],"metadata":{"id":"d4qbxwaMM1X6"},"execution_count":null,"outputs":[]}]}
